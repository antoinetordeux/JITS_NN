{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "######################################################################################################\n## R-script for the plot of the figure 6 of the paper https://doi.org/10.1080/15472450.2019.1621756 ##\n######################################################################################################\n\nrm(list = ls())\nsetwd('C:/Users/antoi/Desktop/data_analysis_JITS_NN/')\ninstall.packages('neuralnet')\nrequire(neuralnet)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "######################################################################################################\n## Functions for training and testing of the neuronal nets\n## a is the number of the neurone(s) on the first layer and b the number on the second.\n## r=1,2,3,4 is the code for the inputs (NN1, NN2, NN3, NN4 in the paper)\n\nsig_ann=function(data,a,b,r){\n\tdata[,6]=sqrt(data[,3]^2+data[,4]^2)\n\tif(r==1) data=data[,6:26]\n\tif(r==2) data=data[,6:46]\n\tif(r>2){ \n\td=matrix(-1,nrow(data),K);pp=NULL\n\tfor(k in 1:K) \n\t\td[,k]=sqrt(data[,6+2*k-1]^2+data[,6+2*k]^2)\n\tfor(i in 1:nrow(data))\n\t\tpp=c(pp,mean(d[i,]));\n\tif(r==3){\n\t\tdata=cbind(data[,6:26],pp)\n\t\tdata=as.data.frame(data);colnames(data)=paste('V',6:27,sep='')}\t\n\tif(r==4){\n\t\tdata=cbind(data[,6:46],pp)\n\t\tdata=as.data.frame(data);colnames(data)=paste('V',6:47,sep='')}}\n\ttr=as.data.frame(data[cc,])\n\tte=as.data.frame(data[!cc,])\n\tf=as.formula(paste(\"V6 ~\", paste(names(tr)[!names(tr) %in% \"V6\"], collapse = \" + \")))\n\th=a;if(b>0)h=c(h,b)\n\tnn=neuralnet(f,data=tr,hidden=h,lifesign=\"none\",stepmax=1e7,linear.output=T)\n\tpr.nn1=as.vector(compute(nn,tr[,2:ncol(tr)])$net.result)\n\tpr.nn2=as.vector(compute(nn,te[,2:ncol(te)])$net.result)\n\tplot(te$V6,pr.nn2,xlab='Real data',ylab='Prediction',main=paste('ANN',a,b),col=4)\n\tlines(tr$V6,pr.nn1,type='p',pch=2,col=2)\n\tabline(a=0,b=1,col=3,lwd=2)\n\treturn=c(mean((tr$V6-pr.nn1)^2),mean((te$V6-pr.nn2)^2))}",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "######################################################################################################\n## Computation of the results\n## B is the number of bootstrap subsampling\n\nB=1\naa=c(1,2,3,4,5,5,6,10) ## tested number of neurone(s) in the first layer\nbb=c(0,0,0,2,2,3,3,4)  ## tested number of neurone(s) in the second layer\npar(mfrow=c(3,3))\n\nfor(r in c(1)){\n\tdata=rbind(as.matrix(read.table(\"close10-16speed\",header=F)),as.matrix(read.table(\"bott10-16speed\",header=F)))\n\tdata=data[sample(1:nrow(data),500,replace=F),] ## Remove to use the full dataset!\n\tcc=((1:length(data[,1]))%%2==0)\n\n\tstr=matrix(-1,B,length(aa))\n\tste=matrix(-1,B,length(aa))\n\tfor(b in 1:B){\n\t\tccc=sample(1:nrow(data),nrow(data),replace=F)\n\t\tfor(i in 1:length(aa)){\n\t\t\tres_ann=sig_ann(data[ccc,],aa[i],bb[i],r)\n\t\t\tstr[b,i]=res_ann[1]\n\t\t\tste[b,i]=res_ann[2]}}\n\tsdtr=apply(str,2,sd);sdte=apply(ste,2,sd)\n\tplot(NA,ylim=range(c(apply(ste,2,mean),apply(str,2,mean))),xlim=c(1,8),ylab=\"Training and testing error\",xlab=\"Network complexity\")\n\tlines(apply(ste,2,mean),col=4,lty=r);lines(apply(str,2,mean),col=2,lty=r)\n\t#write.table(cbind(str,ste),paste(\"trainRB\",r,sep=\"\"),col.names=F,row.names=F,quote=F,sep=\" \")\n}",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "######################################################################################################\n## Plotting of results preliminary computed for the full dataset with B=50 and r=1,2,3,4 (cf. paper)\n\nplot(NA,ylim=c(0,.12),xlim=c(1,8))\nlegend(\"bottomleft\",title=\"NN\",legend=1:4,lty=1:4,col=1)\nfor(r in 1:4){\n\tres=as.matrix(read.table(paste(\"trainRB\",r,sep=\"\")))\n\tstr=res[,1:8];ste=res[,9:16]\n\tlines(apply(ste,2,mean),col=4,lty=r);lines(apply(str,2,mean),col=2,lty=r)}",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}